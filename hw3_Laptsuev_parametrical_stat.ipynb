{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from SALib.analyze import sobol as sobol\n",
    "from SALib.analyze import morris as morris_analyzer\n",
    "\n",
    "from SALib.sample import saltelli as saltelli_sampler\n",
    "from SALib.sample import morris as morris_sampler\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import date_range,Series,DataFrame,read_csv, qcut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "np.set_printoptions(suppress=True)\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.gaussian_process.kernels import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: surrogate modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual dependency is not given, only a data set of inputs and outputs.\n",
    "To perform sensitivity analysis and optimization we are going to use a regression model.\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "* Load data set.\n",
    "* Build several regression models using different techniques: Gaussian Process Regression, Kernel Ridge regression, SVM.\n",
    "* Perform k-fold cross-validation for each model and choose the best.\n",
    "* The most accurate model will be used in all subsequent excersices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Для начала загрузим данные и определим модели которые будем рассматривать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load data set\n",
    "data=pd.read_csv('C://Users/Rpl/Downloads/doe_100.csv', sep=',')\n",
    "\n",
    "regressors = [\"r1\",\"t1\",\"r2\",\"r3\",\"t3\",\"r4\"]\n",
    "output_variables = [\"mass\",\"smax\",\"u2\"]\n",
    "X=data[regressors].as_matrix()\n",
    "#рассматриваемые модели\n",
    "models = []\n",
    "svr = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "kernel_ridge = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     \"alpha\": [1e0, 0.1, 1e-2, 1e-3]},\n",
    "                                 {'kernel': ['chi2'], 'gamma': [1e-3, 1e-4],\n",
    "                     \"alpha\": [1e0, 0.1, 1e-2, 1e-3]},\n",
    "                                 {'kernel': ['cosine'], \n",
    "                     \"alpha\": [1e0, 0.1, 1e-2, 1e-3]},\n",
    "                    {'kernel': ['linear'], \"alpha\": [1e0, 0.1, 1e-2, 1e-3]}]\n",
    "\n",
    "\n",
    "gauss = [\n",
    "                         {'alpha': [1e0, 1e-1, 1e-2, 1e-3], \n",
    "                     'kernel': [ 1.0 * RationalQuadratic(length_scale=b, alpha=a) for a in np.linspace(0.1, 10, num=30) for b in np.linspace(0.1, 5, num=10)]},\n",
    "                          {'alpha': [1e0, 1e-1, 1e-2, 1e-3], \n",
    "                     'kernel': [ ConstantKernel(b, (0.01, 10.0))  * RBF(a) for a in np.linspace(0.1, 10, num=30) for b in np.linspace(0.1, 5, num=10)]},\n",
    "                         {'alpha': [1e0, 1e-1, 1e-2, 1e-3], \n",
    "                     'kernel': [ ConstantKernel(b, (0.01, 10.0)) * (DotProduct(sigma_0=a, sigma_0_bounds=(0.1, 10.0)) ** 2) for a in np.linspace(0.1, 10, num=30) for b in np.linspace(0.1, 5, num=10)]\n",
    "                         }]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Теперь для каждой зависимой переменной (mass,smax,u2) найдем жадным поиском наилучшие параметры модели.После этого выберем модель с наибольшим средним коэф. детермизации полученным после кросс валидации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MODEL\n",
      "Accuracy of model:  0.99711426105\n",
      "Parameters of model\n",
      "{'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "KERNEL_RIDGE MODEL\n",
      "Accuracy of model:  0.99793677911\n",
      "Parameters of model\n",
      "{'alpha': 0.001, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "GAUSS MODEL\n",
      "Accuracy of model:  0.999957258894\n",
      "Parameters of model\n",
      "{'alpha': 0.001, 'kernel': 1**2 * RationalQuadratic(alpha=4.2, length_scale=3.91)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00861745, -0.00014657,  0.03856004]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 72, 'warnflag': 2, 'nit': 20}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    }
   ],
   "source": [
    "y= data[\"mass\"].as_matrix()\n",
    "\n",
    "reg = GridSearchCV(SVR(), svr, n_jobs=-1)\n",
    "reg.fit(X, y)\n",
    "print(\"SVR MODEL\")\n",
    "print(\"Accuracy of model: \",reg.best_score_)\n",
    "print(\"Parameters of model\")\n",
    "print(reg.best_params_)\n",
    "\n",
    "reg = GridSearchCV(KernelRidge(), kernel_ridge, n_jobs=-1)\n",
    "reg.fit(X, y)\n",
    "print(\"KERNEL_RIDGE MODEL\")\n",
    "print(\"Accuracy of model: \",reg.best_score_)\n",
    "print(\"Parameters of model\")\n",
    "print(reg.best_params_)\n",
    "\n",
    "reg = GridSearchCV(GaussianProcessRegressor(), gauss, n_jobs=-1)\n",
    "reg.fit(X, y)\n",
    "print(\"GAUSS MODEL\")\n",
    "print(\"Accuracy of model: \",reg.best_score_)\n",
    "print(\"Parameters of model\")\n",
    "print(reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MODEL\n",
      "Accuracy of model:  0.799853637879\n",
      "Parameters of model\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "KERNEL_RIDGE MODEL\n",
      "Accuracy of model:  0.821965413325\n",
      "Parameters of model\n",
      "{'alpha': 0.001, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "GAUSS MODEL\n",
      "Accuracy of model:  0.842147989342\n",
      "Parameters of model\n",
      "{'alpha': 0.001, 'kernel': 1**2 * RationalQuadratic(alpha=8.63, length_scale=2.82)}\n"
     ]
    }
   ],
   "source": [
    "y= data[\"smax\"].as_matrix()\n",
    "\n",
    "reg = GridSearchCV(SVR(), svr, n_jobs=-1)\n",
    "reg.fit(X, y)\n",
    "print(\"SVR MODEL\")\n",
    "print(\"Accuracy of model: \",reg.best_score_)\n",
    "print(\"Parameters of model\")\n",
    "print(reg.best_params_)\n",
    "\n",
    "reg = GridSearchCV(KernelRidge(), kernel_ridge, n_jobs=-1)\n",
    "reg.fit(X, y)\n",
    "print(\"KERNEL_RIDGE MODEL\")\n",
    "print(\"Accuracy of model: \",reg.best_score_)\n",
    "print(\"Parameters of model\")\n",
    "print(reg.best_params_)\n",
    "\n",
    "reg = GridSearchCV(GaussianProcessRegressor(), gauss, n_jobs=-1)\n",
    "reg.fit(X, y)\n",
    "print(\"GAUSS MODEL\")\n",
    "print(\"Accuracy of model: \",reg.best_score_)\n",
    "print(\"Parameters of model\")\n",
    "print(reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MODEL\n",
      "Accuracy of model:  0.260699837829\n",
      "Parameters of model\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "KERNEL_RIDGE MODEL\n",
      "Accuracy of model:  0.931547404297\n",
      "Parameters of model\n",
      "{'alpha': 0.001, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "GAUSS MODEL\n",
      "Accuracy of model:  0.968403626257\n",
      "Parameters of model\n",
      "{'alpha': 0.01, 'kernel': 0.316**2 * DotProduct(sigma_0=0.1) ** 2}\n"
     ]
    }
   ],
   "source": [
    "y= data[\"u2\"].as_matrix()\n",
    "\n",
    "reg = GridSearchCV(SVR(), svr, n_jobs=-1)\n",
    "reg.fit(X, y)\n",
    "print(\"SVR MODEL\")\n",
    "print(\"Accuracy of model: \",reg.best_score_)\n",
    "print(\"Parameters of model\")\n",
    "print(reg.best_params_)\n",
    "\n",
    "reg = GridSearchCV(KernelRidge(), kernel_ridge, n_jobs=-1)\n",
    "reg.fit(X, y)\n",
    "print(\"KERNEL_RIDGE MODEL\")\n",
    "print(\"Accuracy of model: \",reg.best_score_)\n",
    "print(\"Parameters of model\")\n",
    "print(reg.best_params_)\n",
    "\n",
    "reg = GridSearchCV(GaussianProcessRegressor(), gauss, n_jobs=-1)\n",
    "reg.fit(X, y)\n",
    "print(\"GAUSS MODEL\")\n",
    "print(\"Accuracy of model: \",reg.best_score_)\n",
    "print(\"Parameters of model\")\n",
    "print(reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(GaussianProcessRegressor(kernel = 1.0*RationalQuadratic(alpha=4.2, length_scale=3.91), alpha = 0.001))\n",
    "models.append(GaussianProcessRegressor(kernel = 1.0*RationalQuadratic(alpha=8.63, length_scale=2.82), alpha = 0.001))\n",
    "models.append(GaussianProcessRegressor(kernel = 0.316**2 * DotProduct(sigma_0=0.1) ** 2, alpha = 0.01))\n",
    "\n",
    "for var, model in zip(output_variables, models):\n",
    "    model.fit(X, data[var].as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SALib is a python library for sensitivity analysis.\n",
    "\n",
    "It implements some popular global sensitivity analysis methods: \n",
    "* Morris method - that may be thought of as crude estimation of average absolute value of partial derivative, \n",
    "* Sobol indicies - that show portion of variance in the output that is explained by input,\n",
    "\n",
    "Each method takes **x** and **y** samples as input. But the samples must be properly generated.\n",
    "There are special functions in SALib library to do it.\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "* Calculate Sobol indices:\n",
    "    * Generate **x** and **y** samples using Saltelli’s extension of the Sobol sequence\n",
    "    * Calculate Sobol indices using obtained samples\n",
    "* Calculate screening indices\n",
    "    * Generate **x** and **y** samples for Morris method\n",
    "    * Apply Morris method to generated samples to obtain screening indices\n",
    "* Based on the result try to make your conclusion: what variables influence the output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Теперь мы постараемся понять какие переменные оказывают значимое влияния на различные зависимые переменные,а какие нет. Для этого воспользуемся индексами Соболя и скринингом Морриса. Ниже представленны визуализированные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sobol test for mass\n",
      "Regressors importance \t [ 0.09639896  0.4306505   0.00187223  0.00177059  0.49003731  0.00484022]\n",
      "\n",
      "Sobol test for smax\n",
      "Regressors importance \t [ 0.07509459  0.95383031  0.00822059  0.00491049  0.0764663   0.02087797]\n",
      "\n",
      "Sobol test for u2\n",
      "Regressors importance \t [ 0.34293625  0.47023996  0.00356104  0.01210089  0.17581098  0.01873578]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEKCAYAAADkYmWmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGodJREFUeJzt3X2c1XWd9/HXG5AVFXQaNpS7MwqbFZc31bVqluukCQN7\nGbmPVKRMaSXYxN3LvUrJMoc0Eh9qeLcBZdodl+21toUgaDeM2a666poKQdzkGRUwZcIArYbgc/1x\nDtNhmGHOgXPm8J15Px+PeTzO7/f7/n7n82MO7/me7+9OEYGZmaWpT7ULMDOz/ecQNzNLmEPczCxh\nDnEzs4Q5xM3MEuYQNzNLmEPcDmqSMpJ2SSr5syrpTEkv7WP5Nkl1+1nXckmfyL+eLGlZEet8VtKC\n/Xk/s844xK1bSHq/pP+Q9LqkzZIelfSeIlc/kIsZOl03IgZGRPYAtr17OwsjoqGIdl+OiE8e6PuZ\nFepX7QKs55M0EHgAmAb8P6A/cAbwx2rWZdYTuCdu3eFtQETEv0bOHyPixxGxAkA5n5eUlfSKpHsl\nDSpYX8DfS9qQ//k/bQuk/pLm5ue/LOkrkg4ppqj8MM1x+df3SLpT0mJJWyU9JunYgrbnSFolaYuk\nO/I17V52iaRHC6bHSHpYUoukTZJm5udfJ+nbBe1Oy3872SLpGUlnFiy7VNL6fC3rJV1U/D+39SYO\ncesOa4Cd+XBukHRUu+VTgI8DZwLHAQOBO9u1qQdGAeOAqyWdlZ//eeAU4ETgpPzrzxdZV/uhlguB\n64CjgPXAlwAk1QL3A9cAg/PL3tfRtiQdAfwIeBA4BhgN/KSDdsOAxcAXI6IG+DRwv6RaSYcBtwHj\nImIQcDrwiyL3yXoZh7hVXERsA94P7AIWAK9K+qGkv8w3mQzcGhHNEfEm8FlgUruDmY0R8Yd87/0e\n4KKCdWdFREtEtACzgIuLLE3tpv89Ip6OiF3Ad4GT8/MnACsi4t8jYmdEzAVe6WSb/wvYFBFzI6I1\nIt6IiCc7aPdRYElEPAQQET8Bnsq/F8BO4ARJh0bEbyJiVZH7ZL2MQ9y6RUT8KiI+EREjgf8BDAXm\n5hcPBZoLmjeTO14zZPfqwMvtlg8tWPfFTpaVqjCY3wSOKHiP9me5dHbWywhyPfWuZIALJP02/7OF\nXO/+mPwfsguBfwA2SXpA0vHF7oT1Lg5x63YRsQa4l1yYA2wkF2q7ZYAdwG8K5o0oeD0yv05n626k\nvDbl37PQiI4akgv3UUVs8yXgWxHxlvxPTf5smZsAIuJHETEWOBr4FfC1/azdejiHuFWcpOMl/XN+\nHBhJI8gNhzyWb/J/gSsl1eXHlL8E3Jcf1oDcsMe1kgZIGkNuDP2+gnU/L2mwpMHAtUDbwcMyWQK8\nU9KHJfWV9E/kwrUji4GjJf1j/qDrEZJO6aDdd4BzJY2V1EfSofnz2odKequkD+XHxncA28kNr5jt\nxSFu3WEbcCrwhKRtwH8Cz5E7mAfwDXLB+zNyQxFvAv9YsH4AjwDryB00vCk/hgxwA7mx5OeAZ/Ov\nv1RkXUWdf54faz8fmANsJtfT/nknbbcD5wAfIjc8s4bcQdn27V4GJpI7WPoauWGgT5P7P9kH+Gdg\nQ/79/obc0IrZXtTVQyEk3U3uYM1vIuLETtrcDowH3gAujQgfSTcz6wbF9MTvIXdaV4ckjQdGRcRf\nkbuYY16ZajMzsy50GeIR8XNgyz6aTAS+lW/7BHCkpCH7aG9mZmVSjjHxYex5utWG/DwzM6swH9g0\nM0tYOW6AtYE9z5kdnp+3F0kHcjc6M7NeKyLaX2EMFN8TF3tforzbInL3vUDSacDrEfGbTtoSEWX7\nue6668q6vYPtpyfvX0/eN+9f+j8H2/7tS5c9cUkLyZ3nWivpRXI3COqfy+NYEBEPSpogaR25Uwyn\ndLVNMzMrjy5DPCImF9FmRnnKMTOzUiR9YLO+vr7aJVRUT96/nrxv4P1LXUr71+UVm2V9Mym68/3M\nzHoCSUQnBzb9eDYzq5i6ujqam5u7bmgAZDIZstlsSeu4J25mFZPvQVa7jGR09u+1r5540mPiZma9\nnUPczCxhHhOvsulXTie7MVvSOnVD65j3Fd8s0swc4lWX3Zgl87FM1w0L1/lOtjLFmFlyHOJm1q2u\nmT6dlhLPwChFbV0ds+f1nm+qDnEz61Yt2SzzM6V9+yzFtAr+gTgY+cCmmfVaxx57LDfffDMnnXQS\nAwcOZOrUqbz66qtMmDCBQYMGMXbsWH73u98BcMEFF3DMMcdQU1NDfX09v/zlL9u28+CDDzJmzBgG\nDRrEiBEjuPXWWwFoaWnh3HPPpaamhtraWs4888yy74ND3Mx6te9///v85Cc/Yc2aNSxatIgJEyZw\n4403snnzZnbu3Mntt98OwIQJE1i/fj2vvvoq7373u/noRz/ato3LLruMr33ta2zdupUVK1Zw1lln\nAXDLLbcwYsQIWlpaePXVV5k9e3bZ63eIm1mvdsUVVzB48GCOOeYYzjjjDE499VROPPFE+vfvz3nn\nncczzzwDwKWXXsphhx3GIYccwhe+8AWeffZZtm3bBkD//v1ZuXIl27Zt48gjj+Tkk08G4JBDDmHT\npk288MIL9O3bl/e9731lr98hbma92pAhf34k8IABA/aa3r59O7t27WLmzJmMHj2ao446imOPPRZJ\nbN68GYD777+fJUuWkMlk+MAHPsDjjz8OwFVXXcWoUaMYO3Yso0ePZs6cOWWv3yFuZtaFhQsXsmjR\nIn7605/y+uuvk81m93hgw3ve8x5+8IMf8NprrzFx4kQuuOACAA4//HBuvvlm1q9fz6JFi7j11ltZ\nvnx5WWtziJuZdWH79u0ceuih1NTU8MYbb/DZz34WKXcrkx07drBw4UK2bt1K3759GThwIH379gVg\nyZIlrF+/HoCBAwfSr18/+vQpb+z6FEMz61a1dXUVPQ2wtq6u6La7g7iz6d0+/vGPs2zZMoYNG0Zt\nbS3XX3898+fPb1v+7W9/myuuuIKdO3dy/PHHs3DhQgDWrl3LjBkz2Lx5MzU1NVx++eVlP0PFdzGs\nsoYLG0q+YrP5O80s+96yClVkVj6+i2FpfBdDM7NexiFuZpYwh7iZWcIc4mZmCXOIm5klzCFuZpYw\nh7iZWcIc4mZmCXOIm5klzJfdm1m32p+Hg5eitz1I3CFuZt1qfx4OXtL2e9mDxD2cYma91pw5cxg+\nfDiDBg3iHe94B8uXL2fWrFlccMEFXHzxxQwaNIiTTjqJtWvXcuONNzJkyBAymQw//vGP27Zx7733\n8s53vpNBgwYxevRoFixY0Lbspptu4rTTTmPXrl0AfPWrX+WEE06gtbW1bPvgEDezXmnNmjXcdddd\nPP3002zdupWHHnqIuvwdEBcvXswll1zC66+/zsknn8y4ceOICDZu3Mi1117LJz/5ybbtDBkyhAcf\nfJCtW7dyzz33cOWVV/KLX/wCgM985jMceuih3HDDDaxbt47Pfe5zfPe736V///5l2w+HuJn1Sn37\n9qW1tZUVK1bwpz/9iZEjR3LssccCcMYZZ/DBD36QPn36cP7557N582ZmzpxJ3759mTRpEs3NzWzd\nuhWA8ePHt4X/GWecwdixY3n00UeB3N0Hv/nNb3LbbbfxoQ99iJkzZ3LiiSeWdT8c4mbWK40aNYq5\nc+fS2NjIW9/6ViZPnsymTZuAvR/ZNnjw4LZ7jQ8YMICIYPv27QAsXbqU9773vdTW1lJTU8PSpUvb\nHtsGtD2yrbm5mU996lNl3w+HuJn1WpMmTeLRRx/lxRdfBODqq68uaf3W1lY+8pGPcNVVV/Haa6+x\nZcsWxo8fv8c9wZcsWcJjjz3G2Wefzac//emy1g8OcTPrpdasWcPy5ctpbW2lf//+DBgwoO2xasVq\nbW2ltbWVwYMH06dPH5YuXcrDDz/ctnzz5s1MnTqVb3zjG9x7770sXryYpUuXlnU/fIqhmXWruqF1\nFT0NsG5oXVHt/vjHPzJz5kxWr17NIYccwumnn86CBQv2eOxaZ3YPrRxxxBHcfvvtnH/++bS2tnLu\nuecyceLEtnbTpk3jvPPOY9y4cQB8/etf57LLLuP555+npqam9J3rqJZiHp0kqQGYS67nfndEzGm3\nfBDwHWAk0Be4JSLu7WA7fjxbO348m/VkfjxbaSryeDZJfYA7gXHAGOAiSW9v1+xyYGVEnAx8ALhF\nknv5ZmYVVsyY+CnA2ohojogdwH3AxHZtAhiYfz0QaImIP5WvTDMz60gxIT4MeKlg+uX8vEJ3Au+U\ntBF4Fvin8pRnZmb7Uq4hj3HAMxFxlqRRwI8knRgR29s3bGxsbHtdX19PfX19mUowM+sZmpqaaGpq\nKqptMSG+gdwBy92G5+cVmgJ8GSAi1kt6AXg78FT7jRWGuJmZ7a19B3fWrFmdti1mOOVJYLSkjKT+\nwCRgUbs2zcAHASQNAd4G/Lqkqs3MrGRd9sQjYqekGcDD/PkUw1WSpuUWxwLgBuBeSc/lV7sqIn5b\nsarNzAwockw8IpYBx7ebN7/g9SZy4+JmZtaNfNm9mVnCfEGOmXWr6dOvIZttqdj26+pqmTdv9gFt\n44knnuDaa6/l6aefpl+/ftTX13Pbbbdx9NFHl6nK8nGIm1m3ymZbyGS6vj/J/m9/2gFvY8uWLUyb\nNo1x48bRr18/Lr/8cqZMmVL2m1eVg0PczHqlPn36sG7dOo477jgApkyZwogRI/jiF79IQ0PDHm1n\nzJhx0F7T4jFxM+uVdt+JsBiPPPIIY8aMqWA1+889cTPrlYq9u+Jzzz3H9ddfzwMPPFDhivaPe+Jm\nZp1Yt24dEyZM4I477uD000+vdjkdcoibWa902GGH8eabb7ZNv/LKK3ssb25u5pxzzuG6665j8uTJ\n3V1e0RziZtYrvetd72LhwoXs2rWLZcuW8cgjj7Qt27BhA2effTZXXHEFU6dOrWKVXfOYuJl1q7q6\n2rKcBriv7Rdj7ty5XHLJJdx11118+MMf5rzzzmtbdvfdd/PCCy/Q2NhIY2MjEYEktm7dWqmy91tR\nj2cr25v58Wx78ePZrCfz49lKU5HHs5mZ2cHLIW5mljCHuJlZwhziZmYJc4ibmSXMIW5mljCfJ25m\nFZPJZEq60VRvl8mUdroxOMTNrIKy2Wy1S+jxPJxiZpYwh7iZWcIc4mZmCXOIm5klzCFuZpYwh7iZ\nWcIc4mZmCXOIm5klzCFuZpYwh7iZWcIc4mZmCXOIm5klzCFuZpYwh7iZWcIc4mZmCXOIm5klrKgQ\nl9QgabWkNZKu7qRNvaRnJK2QtLy8ZZqZWUe6fLKPpD7AncDZwEbgSUk/jIjVBW2OBO4CxkbEBkmD\nK1WwmZn9WTE98VOAtRHRHBE7gPuAie3aTAbuj4gNABGxubxlmplZR4oJ8WHASwXTL+fnFXob8BZJ\nyyU9KenichVoZmadK9eDkvsB7wbOAg4HHpP0WESsK9P2zcysA8WE+AZgZMH08Py8Qi8DmyPiD8Af\nJP0MOAnYK8QbGxvbXtfX11NfX19axWZmPVxTUxNNTU1FtVVE7LuB1Bf4FbkDm5uA/wIuiohVBW3e\nDtwBNAB/ATwBXBgRv2y3rejq/XqbhgsbyHwsU9I6zd9pZtn3llWoIjM72EgiItTRsi574hGxU9IM\n4GFyY+h3R8QqSdNyi2NBRKyW9BDwHLATWNA+wM3MrPyKGhOPiGXA8e3mzW83fTNwc/lKMzOzrviK\nTTOzhDnEzcwS5hA3M0uYQ9zMLGEOcTOzhDnEzcwS5hA3M0uYQ9zMLGEOcTOzhDnEzcwS5hA3M0uY\nQ9zMLGEOcTOzhDnEzcwS5hA3M0uYQ9zMLGEOcTOzhDnEzcwS5hA3M0uYQ9zMLGFFPSjZzNJ2zfTp\ntGSzJa1TW1fH7HnzKlOQlY1D3KwXaMlmmZ/JlLTOtBJD36rDwylmZglziJuZJcwhbmaWMI+JJ2jl\nU5toaJhW0jp1dbXMmze7QhWZWbU4xBP0+zf7kcnML2mdbLa00DezNHg4xcwsYQ5xM7OEOcTNzBLm\nEDczS5hD3MwsYQ5xM7OEOcTNzBLm88TLaH/uFLdmw0oylHZjIjOz3RziZbQ/d4obse6pClVjZr1B\nUcMpkhokrZa0RtLV+2j315J2SPq78pVoZmad6TLEJfUB7gTGAWOAiyS9vZN2NwIPlbtIMzPrWDE9\n8VOAtRHRHBE7gPuAiR20uwL4N+DVMtZnZmb7UEyIDwNeKph+OT+vjaShwIcj4quAyleemZntS7lO\nMZwLFI6VO8jNzLpBMWenbABGFkwPz88r9D+B+yQJGAyMl7QjIha131hjY2Pb6/r6eurr60ss2cys\nZ2tqaqKpqamotsWE+JPAaEkZYBMwCbiosEFEHLf7taR7gAc6CnDYM8TNzGxv7Tu4s2bN6rRtlyEe\nETslzQAeJjf8cndErJI0Lbc4FrRfZX+KNjOz0hV1sU9ELAOObzevw0fLRMQnylCXmZkVwfdOMTNL\nmEPczCxhDnEzs4Q5xM3MEuYQNzNLmEPczCxhDnEzs4Q5xM3MEtYjn+wzffo1ZLMtJa1TV1fLvHmz\nK1SRmVll9MgQz2ZbyGQ6vKB0H+tMq1A1ZmaV4+EUM7OEOcTNzBLmEDczS5hD3MwsYQ5xM7OEOcTN\nzBLmEDczS5hD3MwsYQ5xM7OEOcTNzBLmEDczS5hD3MwsYQ5xM7OEOcTNzBLmEDczS5hD3MwsYQ5x\nM7OEOcTNzBLmEDczS5hD3MwsYQ5xM7OEOcTNzBLmEDczS5hD3MwsYQ5xM7OEOcTNzBJWVIhLapC0\nWtIaSVd3sHyypGfzPz+XdEL5SzUzs/a6DHFJfYA7gXHAGOAiSW9v1+zXwN9ExEnADcDXyl2omZnt\nrZie+CnA2ohojogdwH3AxMIGEfF4RPwuP/k4MKy8ZZqZWUeKCfFhwEsF0y+z75C+DFh6IEWZmVlx\n+pVzY5I+AEwB3t9Zm8bGxrbX9fX11NfXl7MEM7PkNTU10dTUVFTbYkJ8AzCyYHp4ft4eJJ0ILAAa\nImJLZxsrDHEzM9tb+w7urFmzOm1bzHDKk8BoSRlJ/YFJwKLCBpJGAvcDF0fE+v2o2czM9kOXPfGI\n2ClpBvAwudC/OyJWSZqWWxwLgGuBtwD/IknAjog4pZKFm5lZkWPiEbEMOL7dvPkFr6cCU8tbmpmZ\ndcVXbJqZJaysZ6eYWe82ffo1ZLMtJa1TV1fLvHmzK1RRz+cQN7OyyWZbyGTmd91wj3WmVaia3sHD\nKWZmCXOIm5klzCFuZpYwh7iZWcIc4mZmCXOIm5klzCFuZpYwh7iZWcIc4mZmCXOIm5klzCFuZpYw\nh7iZWcIc4mZmCXOIm5klzCFuZpawbr+f+LSGhpLa19bVMXvevApVY2aWtm4P8fmZTEntp2WzlSnE\nzKwH8HCKmVnCHOJmZglziJuZJeygf1Dyz369koYLSzsYunL1dkocejezdvx/Lw0HfYhv3/V7Mh8r\n7VPx1M+eqlA1Zr2H/++lwcMpZmYJc4ibmSXMIW5mljCHuJlZwhziZmYJc4ibmSXMIW5mljCHuJlZ\nwhziZmYJc4ibmSWsqMvuJTUAc8mF/t0RMaeDNrcD44E3gEsj4hflLNTMrJymXzmd7MZsSevUDa1j\n3lcOrofUdBnikvoAdwJnAxuBJyX9MCJWF7QZD4yKiL+SdCowDzitQjW32fj8RoaeMLTSb1M1PXn/\nmpqaqK+vr3YZFdPT968nfDazG7Od3hums/1b8r8fo2HVtJLep66ulnnzZu9XjcUopid+CrA2IpoB\nJN0HTARWF7SZCHwLICKekHSkpCER8ZtyF1yoJ3yQ9qUn719PD7l97d/06deQzbaUtL1KB0GpevJn\nEzrfv9+/2Y9MZn5J28pmSwv9UhUT4sOAlwqmXyYX7PtqsyE/r6Ihbge/zr6yrluxjsdXPd7hOgfj\nV9ZyymZbDrogsHQd9LeitYPHNdOn01LiM09/tGEl58yesNf81xa+RmZyx19lq/WVdX/2779ee5Eh\no0fuNX9ff6R8z+3y25/f3ZoNK8mQ/i9CEbHvBtJpQGNENOSnZwJReHBT0jxgeUR8Lz+9Gjiz/XCK\npH2/mZmZdSgi1NH8YnriTwKjJWWATcAk4KJ2bRYBlwPfy4f+6x2Nh3dWhJmZ7Z8uQzwidkqaATzM\nn08xXCVpWm5xLIiIByVNkLSO3CmGUypbtpmZQRHDKWZmdvBK9opNSTdIelHS1mrXUg750zL/oWB6\nqaQtkhZVs65KkDRA0mJJqyQ9L+ngOXeuTPK/v2fy+/cvkpIdSiz8bEoaKelpSf+d37cee9qMpEWS\nnqt2HV1JNsSBxcBfV7uIMqoBPlUwfRPwsSrVUmkCbomIdwDvAt4vaVyVayq38yPiXRFxAvBW4Pxq\nF3QACj+bm4DTIuLdwKnATElHV62yClDOeUASHcRkQlxSRtJqSd+U9DywodIXE3WzLwPH5Xs4cyJi\nObC92kWVS+HvD3gCWAcQEX8C/hsYXs36DlQHn8+a/PxDgP5AyuOWbZ9N4IaI2JGfP4DcH+SkdfC7\nGwFcCdxQ5dKKktp54qOBiyPiyWoXUgEzgTH5Hk5PtdfvT9JRwLnk7s2Tuj32T9Iyct8WlwL/Vs3C\nDtAen01Jw4ElwCjgMxHxSjWLK5O2352kW4Gbgd9XuaaiJNMTz2vuoQHeWzS3C/C+wEJgbkRkq1ZV\n+eyxf/lrK44B/gI4q2pVlVlEvBwRJ5ELvksl/WW1ayqD5nyAn0zuPlCLyH3LOOi/aaQW4m9UuwA7\nIO1/fwuAX0XEHdUopgL2+nxGRCu56ygmdn85lZXvga8Azqh2LWWw+3d3GvAeSb8GHgXeJumn1Sur\na6mFeEd/FQ/6v5RF2gYMbDcviZ5ACdr2RdINwKCIuLKK9ZSbACQdvvtgn6R+wN+y5w3jUtP22ZQ0\nTNKh+dc1wPuBX1WxtnIRQETMi4jhEXEc+X2LiIP6W1RqY+JtB4ckzQEmAwMkvQh8PSK+WLXKDlBE\n/FbSf+ZPaVoKvBc4Hjgiv39/HxE/qmqRBy4gFwTANcAqSc/k598ZEd+oZnFlsPvzeTiwSFJ/ch2l\n5eRuz5yk/GfzP/KfzR1A34IzJm+KiJXVq65skj3w7It9zMwSltpwipmZFXCIm5klzCFuZpYwh7iZ\nWcIc4mZmCXOIm5klzCFuZpYwh7iZWcL+P//m4AQLmYEOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29587c17208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sobol\n",
    "problem = {\n",
    "    'num_vars': 6,\n",
    "    'names': data.columns.values[:6],\n",
    "    'bounds': np.array([[10.0, 110.0],\n",
    "                        [4.0, 50.0],\n",
    "                        [120.0, 140.0],\n",
    "                        [150.0, 168.0],\n",
    "                        [4.0, 50.0],\n",
    "                        [170.0, 200.0]]),\n",
    "    'groups': None\n",
    "    }\n",
    "\n",
    "index = np.arange(6)\n",
    "bw = (1-0.3)/3\n",
    "opacity = 0.6\n",
    "colors =['r', 'g', 'b']\n",
    "inputs = saltelli_sampler.sample(problem, 1000)\n",
    "for i, var, model in zip(range(3), output_variables, models):\n",
    "    output = model.predict(inputs)\n",
    "    Si = sobol.analyze(problem, output)\n",
    "    print(\"Sobol test for \"+var)\n",
    "    print(\"Regressors importance \\t\", Si[\"ST\"])\n",
    "    print()\n",
    "    plt.bar(index + bw*i, Si[\"ST\"], bw, label=var, color=colors[i], alpha = opacity)   \n",
    "plt.xticks(index + (1-0.3)/2, [\"r1\",\"t1\",\"r2\",\"r3\",\"t3\",\"r4\"])\n",
    "plt.legend()\n",
    "plt.title(\"Sobol indicies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morris test for mass\n",
      "Regressors importance \t [ 0.15385203  0.35296957  0.02564477  0.02487814  0.40071071  0.04194477]\n",
      "\n",
      "Morris test for smax\n",
      "Regressors importance \t [ 0.15123698  0.54094346  0.04105012  0.03671586  0.15259425  0.07745932]\n",
      "\n",
      "Morris test for u2\n",
      "Regressors importance \t [ 0.3005373   0.34369376  0.02994899  0.05542317  0.2036807   0.06671608]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEKCAYAAADkYmWmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG9BJREFUeJzt3Xt4VPW97/H3N1yOqKAxbFFuE4RdqmwRb3ilRq0Q2Y9F\nzlGK1BseMewKez+eXSu1jzVUNhWPF7RYA8qxtpZje6qPRTHIbiVqj5eD1CtCA8hEBBSJl4i3IHzP\nH7MShzhJZsJMJr/k83qePM+stX6z5ruSyWfW/NZvrWXujoiIhKkg3wWIiEjbKcRFRAKmEBcRCZhC\nXEQkYApxEZGAKcRFRAKmEJegmNkUM1ue7zpyoTNvm+SOaZy47CsziwOHAf3d/YOk+S8DxwDF7v52\nnsprqOUo4A7gBMCAjcAN7q7QlKBpT1yywYFNwEUNM8zsn4Be0bKMmVm3dOZl4DHgSaAfcCjwr0Bd\nG+qyfahBJOsU4pItvwUuS5q+DHgguYGZ9TGz35jZdjPbZGY/TVp2mZn91cxuN7MdwI0tzHs26Xl3\nmNl7Zvaxmb0a7XHT5HWLgGLgPnf/Kvp53t2fS2ozwcxejtaz3szGRvNXmtmcqI5PgSHRdiw2s61m\nttnMbkoOdzO7wszeNLNaM6s0s8FJy/aYWZmZVZvZB2a2oMnv4Nk02xaY2W1m9r6ZbTSzq6P2+p/u\nYvQHl2x5AehtZsOjIPk+8CCJrosGC4DeJAK1BLjUzKYmLT8J2EBiT/k/WpjnAFHQng4Mc/eDgElA\nbdPC3L02WsfvorA+NHm5mY0m8YHz79F6vgPEk5pcDFwZ1f521PZL4AjgWOCcaDlmNgGYBZwP/APw\nLPC/m5T0z8DxJLqaJjV8YCRvWxptrwLGASOB46LXU99oF6QQl2xq2Bs/B1gLbG1YkBTss9z9M3ev\nAW4DLkl6/hZ3/5W773H3L1uY12AXiWA9yszM3f/u7u81U9uZJLp8bgW2mtnTZjY0WnYFsNjdnwJw\n923uXp303F+7+zp33wMcApwLXOPuX7j7DmA+MDlqWwb8wt2ro/Y3A6PMbFDS+n7h7p+4+2ZgJTCq\nmZpbanshcGdU68fR60gXpBCXbHoQmAJcDvymybK+QHcSe7INaoABSdObU6wz1TwA3H0lib37u4H3\nzKzCzA5spu1Wd/9Xd/9HIAZ8mlTjIBIHOpuTXEMM6AFsi7o4PgQqSOx1Nyy/M1r2AYlvBt5kO5M/\naD4DUtbcStv+Tepq9vcknZtCXLImGoGyicSe6iNNFu8gseccS5oXA7YkryLValt5zQXufgJwFDAc\nuDaNOreQCP5/imZtBoY2/4y9atgMfAEUufsh7l7o7ge7+8ho+dtAWbSsYfmB7v5Ca3VlaBswMGl6\ncHMNpXNTiEu2XQGc5e6fJ8+Muhb+APyHmR1oZjHgGhJdMG1iZieY2Wgz6w58TiJc96Rod7CZlZvZ\nUEvoG9X5fNRkMTDVzM6Mlvc3s2+lek13fxdYAdxhZr2j9keY2XeiJguB6xsOsJrZQWZ2QVu3sQV/\nAP4tqvVg4Mc5eA0JgEJcsqFxT9XdN7n731ItIzGs7zPgLeAZ4EF3v38fXrcPcC/wAYlvADuA/5mi\nXT2Jg6n/CXwMvEYi8KdGNa+KHs+Pllfx9TeGVN8ELgV6Am9Gr/1/SIyTx90fJdE//ZCZfRS9VmnS\nczM5+Ni0bfL0vSQ+TF4DVgPLgK+iD0vpQtI62cfMSkm8wQtIHACal6JNCYmTKXoA77v7mdktVUSa\nE/2P3uPuQ/Jdi7SvVkM8GlVQDZxNYrTBKmCyu69LanMQ8Bww1t23mFnf6Ki9iOSAme1HYsTNChLf\nAv4IPOfu/57XwqTdpdOdMhpY7+417r4LeAiY0KTNFODh6IARCnCRnDNgNonunNXAGuDGvFYkedE9\njTYD2Hv40jskgj3Zt4AeZraSxBCou9y9zQesRKRl0YHjpv+H0gWlE+Lpruc44CzgAOB5M3ve3Tdk\naf0iIpJCOiG+hb3HoA5k77G9kNg73+HuXwBfmNkzJE4T3ivEzUynBYuItIG7p7z4Wjp94quAYWYW\nM7OeJE4vXtqkzZ+A082sm5ntT+J6F2ubKSRrPzfeeGNW19fRfjrz9nXmbdP2hf/T0bavJa3uibv7\nbjObQeIoeMMQw7VmVpZY7IvcfZ2ZPUlizOpuYJG7v9naukVEZN+k1SfuiQvnD28yb2GT6VtJXFxI\nRETaSdBnbJaUlOS7hJzqzNvXmbcNtH2hC2n72vX2bImrherYpohIJswMb+bAZraGGIqIfENxcTE1\nNTX5LiMYsViMeDye0XO0Jy4iORPtQea7jGA09/tqaU886D5xEZGuTiEuIhIwhbiISMAU4iIiAdPo\nFBFpV9dPn05thiMwMlFUXMzcioqcrb+jUYiLSLuqjcdZGIu13rCNynL4AdERqTtFRLqsIUOGcOut\nt3LMMcfQu3dvpk2bxvbt2xk/fjx9+vRh7NixfPzxxwBMmjSJww8/nMLCQkpKSnjzza8vD/XEE08w\nYsQI+vTpw6BBg7j99tsBqK2t5bzzzqOwsJCioiLOOOOMrG+DQlxEurRHHnmEv/zlL1RXV7N06VLG\njx/PzTffzI4dO9i9ezd33XUXAOPHj2fjxo1s376d4447jh/84AeN67jyyiu59957qaur44033uCs\ns84C4LbbbmPQoEHU1tayfft25s6dm/X6FeIi0qXNnDmTvn37cvjhhzNmzBhOOukkRo4cSc+ePZk4\ncSIvv/wyAJdffjn7778/PXr04Gc/+xmvvvoqn3zyCQA9e/ZkzZo1fPLJJxx00EGMGjUKgB49erBt\n2zY2bdpEt27dOO2007Jev0JcRLq0fv36NT7u1avXN6Z37tzJnj17mDVrFsOGDePggw9myJAhmBk7\ndiRuJ/zwww+zbNkyYrEYZ555Ji+88AIAP/7xjxk6dChjx45l2LBhzJs3L+v1K8RFRFqxZMkSli5d\nylNPPcVHH31EPB7f64YNxx9/PI8++ijvv/8+EyZMYNKkSQAccMAB3HrrrWzcuJGlS5dy++23s3Ll\nyqzWphAXEWnFzp072W+//SgsLOTTTz/lJz/5CWaJS5ns2rWLJUuWUFdXR7du3ejduzfdunUDYNmy\nZWzcuBGA3r170717dwoKshu7GmIoIu2qqLg4p8MAi4qL027bEMTNTTe49NJLWb58OQMGDKCoqIib\nbrqJhQu/vi/Ob3/7W2bOnMnu3bsZPnw4S5YsAWD9+vXMmDGDHTt2UFhYyNVXX531ESq6iqGI5Iyu\nYpiZtlzFUHvieTb9munEt8Yzek5x/2Iq7ug6Z6SJSPMU4nkW3xondnFmZ6/FH4znphgRCY4ObIqI\nBEwhLiISMIW4iEjAFOIiIgFTiIuIBEwhLiISMIW4iEjANE5cRNpVW05wy0RXOxkurRA3s1JgPok9\n98XuPq/J8jOAPwFvRbMecfc52SxURDqHtpzgltH6u9jJcK12p5hZAbAAGAeMAC4ys2+naPqMux8X\n/SjARaTDmzdvHgMHDqRPnz4ceeSRrFy5ktmzZzNp0iQuueQS+vTpwzHHHMP69eu5+eab6devH7FY\njD//+c+N6/j1r3/NUUcdRZ8+fRg2bBiLFi1qXHbLLbdw8skns2fPHgDuuecejj76aOrr67O2Den0\niY8G1rt7jbvvAh4CJqRol/ryXyIiHVB1dTV33303q1evpq6ujieffJLi6AqIjz/+OJdddhkfffQR\no0aNYty4cbg7W7du5YYbbuCqq65qXE+/fv144oknqKur4/777+eaa67hlVdeAeDaa69lv/32Y86c\nOWzYsIGf/vSn/O53v6Nnz55Z2450QnwAsDlp+p1oXlOnmNkrZrbMzI7KSnUiIjnSrVs36uvreeON\nN/jqq68YPHgwQ4YMAWDMmDF897vfpaCggAsvvJAdO3Ywa9YsunXrxuTJk6mpqaGurg6Ac889tzH8\nx4wZw9ixY3n22WeBxNUHH3jgAe68806+973vMWvWLEaOHJnV7cjW6JTVwGB3H0Wi6+XRLK1XRCQn\nhg4dyvz58ykvL+fQQw9lypQpbNu2DfjmLdv69u3beK3xXr164e7s3LkTgMrKSk455RSKioooLCyk\nsrKy8bZtQOMt22pqavjhD3+Y9e1I58DmFmBw0vTAaF4jd9+Z9LjSzH5lZoe4+wdNV1ZeXt74uKSk\nhJKSkgxLFhHJjsmTJzN58mR27tzJVVddxXXXXcfQoUPTfn59fT0XXHABDz74IBMmTKCgoICJEyfu\ndU3wZcuW8fzzz3P22Wfzox/9iIqK1kfOVFVVUVVVlVYN6YT4KmCYmcWAbcBk4KLkBmbWz93fix6P\nJnGziW8EOOwd4iIi+VJdXc2WLVs47bTT6NmzJ7169Wo8AJmu+vp66uvr6du3LwUFBVRWVrJixQqO\nPvpoAHbs2MG0adO4//77OfHEExk5ciSVlZWce+65La636Q7u7Nmzm23baoi7+24zmwGs4OshhmvN\nrCyx2BcBF5jZvwC7gM+B77e2XhHpmor7F+d0GGBx/+K02n355ZfMmjWLdevW0aNHD0499VQWLVq0\n123XmtPQtXLggQdy1113ceGFF1JfX895553HhAlfj/soKytj4sSJjBs3DoD77ruPK6+8ktdff53C\nwsLMNy5VLbo9W36Vfr804zGzNQ/WsPz3y3NUkUj26PZsmWnL7dl02r2ISMAU4iIiAVOIi4gETCEu\nIhIwhbiISMAU4iIiAVOIi4gETCEuIhIwhbiISMB0ezYRaVfTp19PPF6bs/UXFxdRUTF3n9bx4osv\ncsMNN7B69Wq6d+9OSUkJd955J4cddliWqswehbiItKt4vJZYrPXrk7R9/WX7vI4PP/yQsrIyxo0b\nR/fu3bn66quZOnUqlZWVWagwuxTiItIlFRQUsGHDBo444ggApk6dyqBBg/j5z39OaWnpXm1nzJjR\nYS+brT5xEemSGq5EmI6nn36aESNG5LCattOeuIh0SeleXfG1117jpptu4rHHHstxRW2jPXERkWZs\n2LCB8ePH88tf/pJTTz013+WkpBAXkS5p//3357PPPmucfvfdd/daXlNTwznnnMONN97IlClT2ru8\ntCnERaRLOvbYY1myZAl79uxh+fLlPP30043LtmzZwtlnn83MmTOZNm1aHqtsnfrERaRdFRcXZWUY\nYEvrT8f8+fO57LLLuPvuuzn//POZOHFi47LFixezadMmysvLKS8vx90xM+rq6nJVdpvp9mx5ptuz\nSWem27NlRrdnExHpYhTiIiIBU4iLiARMIS4iEjCFuIhIwBTiIiIB0zhxEcmZWCyW0YWmurpYLLPh\nxqAQF5Ecisfj+S6h01N3iohIwBTiIiIBSyvEzazUzNaZWbWZXddCuxPNbJeZ/dfslSgiIs1pNcTN\nrABYAIwDRgAXmdm3m2l3M/BktosUEZHU0tkTHw2sd/cad98FPARMSNFuJvBHYHsW6xMRkRakE+ID\ngM1J0+9E8xqZWX/gfHe/B9B4IhGRdpKtIYbzgeS+8maDvLy8vPFxSUlJh72DtEhncv306dRmONyv\nqLiYuRUVuSlIWlRVVUVVVVVabdMJ8S3A4KTpgdG8ZCcAD1liVH9f4Fwz2+XuS5uuLDnERaR91Mbj\nLMzwRJIyjfHOm6Y7uLNnz262bTohvgoYZmYxYBswGbgouYG7H9Hw2MzuBx5LFeAiIpJdrYa4u+82\nsxnAChJ96Ivdfa2ZlSUW+6KmT8lBnSIikkJafeLuvhwY3mTewmbaXpGFukREJA06Y1NEJGAKcRGR\ngCnERUQCphAXEQmYQlxEJGAKcRGRgCnERUQCphAXEQmYQlxEJGAKcRGRgCnERUQCphAXEQlYtm4K\nIbTtwvvVW9YQI7PrPIuINFCIZ1FbLrw/aMNLOapGRLoCdaeIiARMIS4iEjB1pwRozUvbKC0ty+g5\nxcVFVFTMzVFFIpIvCvEAff5Zd2KxlDdWalY8nlnoi0gY1J0iIhIwhbiISMAU4iIiAVOIi4gETCEu\nIhIwhbiISMAU4iIiAVOIi4gETCEuIhIwhbiISMDSCnEzKzWzdWZWbWbXpVj+PTN71cxeNrP/Z2an\nZb9UERFpqtVrp5hZAbAAOBvYCqwysz+5+7qkZn9296VR+6OBPwBH5qBeERFJks6e+GhgvbvXuPsu\n4CFgQnIDd/8safJAYE/2ShQRkeakE+IDgM1J0+9E8/ZiZueb2VrgMeCK7JQnIiItydqlaN39UeBR\nMzsdmAOck6pdeXl54+OSkhJKSkqyVUKj6dOvJx6vzeg5ut62iHQUVVVVVFVVpdU2nRDfAgxOmh4Y\nzUvJ3f9qZkeY2SHu/kHT5ckhnivxeK2uty0iwWq6gzt79uxm26bTnbIKGGZmMTPrCUwGliY3MLOh\nSY+PA3qmCnAREcmuVvfE3X23mc0AVpAI/cXuvtbMyhKLfRHw38zsUqAe+ByYlMuiRUQkIa0+cXdf\nDgxvMm9h0uNbgFuyW5qIiLRGZ2yKiARMIS4iEjCFuIhIwBTiIiIBU4iLiARMIS4iEjCFuIhIwBTi\nIiIBU4iLiARMIS4iEjCFuIhIwBTiIiIBU4iLiARMIS4iEjCFuIhIwBTiIiIBU4iLiARMIS4iEjCF\nuIhIwBTiIiIBU4iLiARMIS4iEjCFuIhIwBTiIiIBU4iLiARMIS4iEjCFuIhIwBTiIiIBSyvEzazU\nzNaZWbWZXZdi+RQzezX6+auZHZ39UkVEpKlWQ9zMCoAFwDhgBHCRmX27SbO3gO+4+zHAHODebBcq\nIiLflM6e+GhgvbvXuPsu4CFgQnIDd3/B3T+OJl8ABmS3TBERSaV7Gm0GAJuTpt8hEezNuRKo3Jei\nRCRM06dfTzxem9FziouLqKiYm6OKOr90QjxtZnYmMBU4vbk25eXljY9LSkooKSnJZgkikkfxeC2x\n2MIMn1OWo2rCVVVVRVVVVVpt0wnxLcDgpOmB0by9mNlIYBFQ6u4fNrey5BAXEZFvarqDO3v27Gbb\nptMnvgoYZmYxM+sJTAaWJjcws8HAw8Al7r6xDTWLiEgbtLon7u67zWwGsIJE6C9297VmVpZY7IuA\nG4BDgF+ZmQG73L2lfnMREcmCtPrE3X05MLzJvIVJj6cB07JbmoiItEZnbIqIBEwhLiISMIW4iEjA\nFOIiIgFTiIuIBEwhLiISMIW4iEjAFOIiIgFTiIuIBEwhLiISMIW4iEjAFOIiIgFTiIuIBCyrd/ZJ\nR1lpaUbti4qLmVtRkaNqRKQ5z7y1htLvZ/b/umbdTmKxHBUkKbV7iC/M8C985FPL+JveSCLtbuee\nz4ldnNk/0kvPvJSjaqQ57R7imdIbSUSkeeoTFxEJmEJcRCRgCnERkYApxEVEAqYQFxEJmEJcRCRg\nCnERkYApxEVEAqYQFxEJmEJcRCRgCnERkYApxEVEApZWiJtZqZmtM7NqM7suxfLhZvacmX1hZv8j\n+2WKiEgqrV7F0MwKgAXA2cBWYJWZ/cnd1yU1qwVmAufnpEoREUkpnT3x0cB6d69x913AQ8CE5Abu\nvsPdVwNf5aBGERFpRjohPgDYnDT9TjRPRETyTAc2RUQCls6dfbYAg5OmB0bz2qT8pa/vulPSvz8l\n/fu3dVUiIp1SVVUVVVVVabVNJ8RXAcPMLAZsAyYDF7XQ3lpaWfkJJ6RVmIhIV1VSUkJJSUnj9OzZ\ns5tt22qIu/tuM5sBrCDR/bLY3deaWVlisS8ys37AS0BvYI+Z/RtwlLvv3KctERGRFqV1o2R3Xw4M\nbzJvYdLj94BB2S1NRERaowObIiIBU4iLiARMIS4iEjCFuIhIwNI6sCki0tlMv2Y68a3xjJ5T3L+Y\nijsqclNQGynERaRLim+NE7s4ltlzHoznpph9oO4UEZGAKcRFRAKm7hQRkTSteWkbpaVlGT2nuLiI\nioq5OapIIS4ikrbPP+tOLLaw9YZJ4vHMQj9T6k4REQmYQlxEJGDqThFpZ9OnX088XpvRc3Ldryrh\nUoiLtLN4vLbD9atKuNSdIiISMIW4iEjAFOIiIgFTn7iIBO/66dOpjcczek71ljXEyOzaKR2RQlxy\nqrNcKU46ttp4nIWxzAJ50IaXclRN+1KIS051livFNactH1Jr1u0kw7wRaZZCXGQftOVD6qVnOsce\noHQMOrApIhIw7YlLh9MRrxQn0lEpxCVt7TUCoCNeKU6ko1KIS9o6+wiArjxMTcKlEBeJdPYPKemc\ndGBTRCRgCnERkYClFeJmVmpm68ys2syua6bNXWa23sxeMbNR2S1TRERSaTXEzawAWACMA0YAF5nZ\nt5u0ORcY6u7/CJQB7XLO9NbXt7bHy+RNZ96+zrxtoO0LXUjbl86e+GhgvbvXuPsu4CFgQpM2E4Df\nALj7i8BBZtYvq5WmENIvui068/Z15m0DbV/oQtq+dEJ8ALA5afqdaF5LbbakaCMiIlmmA5siIgEz\nd2+5gdnJQLm7l0bTswB393lJbSqAle7++2h6HXCGu7/XZF0tv5iIiKTk7pZqfjon+6wChplZDNgG\nTAYuatJmKXA18Pso9D9qGuAtFSEiIm3Taoi7+24zmwGsINH9stjd15pZWWKxL3L3J8xsvJltAD4F\npua2bBERgTS6U0REpOMK9sCmmc0xs7fNrC7ftWSDmR1kZv+SNF1pZh+a2dJ81pULZtbLzB43s7Vm\n9rqZdbpryEZ/v5ej7fuVmQXblZj83jSzwWa22sz+Fm1bp718pJktNbPX8l1Ha4INceBx4MR8F5FF\nhcAPk6ZvAS7OUy25ZsBt7n4kcCxwupmNy3NN2Xahux/r7kcDhwIX5rugfZD83twGnOzuxwEnAbPM\n7LC8VZYDljARCGIHMZgQN7NYdOr/A2b2OrAl1cHTgP0COCLaw5nn7iuBnfkuKluS/37Ai8AGAHf/\nCvgbMDCf9e2rFO/Pwmh+D6AnEHK/ZeN7E5gTnfQH0IvEB3LQUvztBgHXAHPyXFpaQrsU7TDgEndf\nle9CcmAWMCLaw+msvvH3M7ODgfOA+XmrKnv22j4zW07i22Il8Md8FraP9npvmtlAYBkwFLjW3d/N\nZ3FZ0vi3M7PbgVuBz/NcU1qC2ROP1HTSAO8qapoEeDdgCTDf3eN5qyp79tq+6NyKw4H/ApyVt6qy\nzN3fcfdjSATf5Wb2D/muKQtqogAfReI6UEtJfMvo8N80QgvxT/NdgOyTpn+/RcDf3f2X+SgmB77x\n/nT3ehLnUTS93lDwoj3wN4Ax+a4lCxr+dicDx5vZW8CzwLfM7Kn8ldW60EI81adih/+kTNMnQO8m\n84LYE8hA47aY2Rygj7tfk8d6ss0AzOyAhoN9ZtYd+GdgXT4L20eN700zG2Bm+0WPC4HTgb/nsbZs\nMQB3r3D3ge5+BNG2uXuH/hYVWp9448EhM5sHTAF6mdnbwH3u/vO8VbaP3P0DM3suGtJUCZwCDAcO\njLbvv7v7f+a1yH3nkAgC4HpgrZm9HM1f4O7/K5/FZUHD+/MAYKmZ9SSxo7SSdro8cy5E783/G703\ndwHdkkZM3uLua/JXXdYEe+BZJ/uIiAQstO4UERFJohAXEQmYQlxEJGAKcRGRgCnERUQCphAXEQmY\nQlxEJGAKcRGRgP1/e+Ke7AQSJ/oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29587c1bd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Morris\n",
    "inputs = morris_sampler.sample(problem, 1000,num_levels=4, grid_jump=2)\n",
    "\n",
    "for i, var, model in zip(range(3), output_variables, models):\n",
    "    output = model.predict(inputs)\n",
    "    Si = morris_analyzer.analyze(problem, inputs, output, num_levels=4, grid_jump=2)\n",
    "    print(\"Morris test for \"+var)\n",
    "    w= Si[\"mu_star\"]/sum(Si[\"mu_star\"])\n",
    "    print(\"Regressors importance \\t\", w)\n",
    "    print()\n",
    "    plt.bar(index + bw*i, w, bw, label=var, color=colors[i], alpha = opacity)\n",
    "    \n",
    "plt.xticks(index + (1-0.3)/2, [\"r1\",\"t1\",\"r2\",\"r3\",\"t3\",\"r4\"])\n",
    "plt.legend()\n",
    "plt.title(\"Morris Screening\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Значимыми переменными оказались: r1, t1, t3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final goal is to optimize the mass of the rotating disk. It will be done with GTOpt optimizer via approximation the surrogate model constructed. We assume that surrogate model is of reasonable quality. The optimization problem for full parameter space is prepared for you.\n",
    "\n",
    "The following optimization problem should be solved:\n",
    "\n",
    "$$\n",
    "{\\rm mass} \\rightarrow \\min_x \\\\\n",
    "\\mbox{subject to} \\quad S_{max}(x) \\le 600 \\\\\n",
    "\\qquad \\qquad U_2(x) \\le 0.3\n",
    "$$\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "* Perform optimization by running code below\n",
    "* Change optimization problem statement in order to include only important variables into optimization problem statement\n",
    "* Compare the results of optimization for two formulations considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В данном задании нам предстоит минимизировать массу диска. Из прошлых заданий мы узнали что на массу диска по большей части влияют 3 регрессора:r1,t1,t3. Посмотрим на данную модель минимазации массы сначала со всеми переменными а потом только со значимыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: array([ 20.85490044])\n",
      "     jac: array([ -36.10229492,   89.27148438,  -23.296875  ,   83.09667969,\n",
      "        -42.43017578, -110.16357422,    0.        ])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 7553\n",
      "     nit: 482\n",
      "    njev: 478\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([  63.69540421,   15.47277287,  124.34149366,  150.00578785,\n",
      "         40.08380953,  194.70427393])\n"
     ]
    }
   ],
   "source": [
    "#Perform optimization by running code below\n",
    "regressors =[\"r1\",\"t1\",\"r2\",\"r3\",\"t3\",\"r4\"]\n",
    "X=data[regressors].as_matrix()\n",
    "for var, model in zip(output_variables, models):\n",
    "    model.fit(X, data[var].as_matrix())\n",
    "    \n",
    "result =minimize(lambda x: models[0].predict(x.reshape(1, -1)), [109.0, 32.0, 123.0, 154.0, 6.0, 198.0],\n",
    "                 bounds=problem['bounds'],\n",
    "                 constraints=[{'type': 'eq',\n",
    "                               'fun' : lambda x: 600 - models[1].predict(x.reshape(1, -1))},\n",
    "                             {'type': 'eq',\n",
    "                               'fun' : lambda x: 0.3 - models[2].predict(x.reshape(1, -1))},\n",
    "                             ],\n",
    "                options={'maxiter':1000})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: array([ 13.62229933])\n",
      "     jac: array([-0.02017212,  0.20278168,  0.15844727,  0.        ])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 75\n",
      "     nit: 14\n",
      "    njev: 14\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 50.01736548,  19.97123834,   4.        ])\n"
     ]
    }
   ],
   "source": [
    "#Change optimization problem statement in order to include only important variables into optimization problem statement\n",
    "regressors =[\"r1\",\"t1\",\"t3\"]\n",
    "X=data[regressors].as_matrix()\n",
    "for var, model in zip(output_variables, models):\n",
    "    model.fit(X, data[var].as_matrix())\n",
    "    \n",
    "result =minimize(lambda x: models[0].predict(x.reshape(1, -1)), [109.0, 32.0, 6.0],\n",
    "                 bounds=np.array([[10.0, 110.0],\n",
    "                        [4.0, 50.0],\n",
    "                        [4.0, 50.0]]),\n",
    "                 constraints=[{'type': 'eq',\n",
    "                               'fun' : lambda x: 600 - models[1].predict(x.reshape(1, -1))},\n",
    "                             {'type': 'eq',\n",
    "                               'fun' : lambda x: 0.3 - models[2].predict(x.reshape(1, -1))},\n",
    "                             ])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мы пришли к тому что убрав не значимые регрессоры (переменные которые слабо влияют на массу диска) нам удалось уменьшить массу диска при выполнении оптимизационной задачи."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
